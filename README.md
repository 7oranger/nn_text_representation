# Neural networks for text representation


## 2016

* Joulin, Armand, et al. "[Bag of Tricks for Efficient Text Classification](https://arxiv.org/abs/1607.01759)." arXiv preprint arXiv:1607.01759 (2016).
* 
* Hill, Felix, Kyunghyun Cho, and Anna Korhonen. "[Learning distributed representations of sentences from unlabelled data](http://arxiv.org/abs/1602.03483)." arXiv preprint arXiv:1602.03483 (2016).
* Ghosh, Shalini, et al. "[Contextual LSTM (CLSTM) models for Large scale NLP tasks](https://arxiv.org/abs/1602.06291)." arXiv preprint arXiv:1602.06291 (2016). [Contextual LSTM]
* Miyamoto, Yasumasa, Kyunghyun Cho. "[Gated Word-Character Recurrent Language Model](https://arxiv.org/abs/1606.01700)." arXiv preprint arXiv:1606.01700 (2016) [Combine word and character embeddings]
* Jozefowicz, Rafal, et al. "[Exploring the limits of language modeling](https://arxiv.org/abs/1602.02410)." arXiv preprint arXiv:1602.02410 (2016). [Character, CNN, LSTM]
* Conneau, Alexis, et al. "[Very Deep Convolutional Networks for Natural Language Processing](http://arxiv.org/abs/1606.01781)." arXiv preprint arXiv:1606.01781 (2016). [Deep CNN]
* Cao, K. and Rei, M. "[A Joint Model for Word Embedding and Word Morphology](http://arxiv.org/abs/1606.02601)." arXiv preprint arXiv:1606.02601(2016). [Character, LSTM, Morphology]

## 2015
* Lai, Siwei, et al. "[Recurrent Convolutional Neural Networks for Text Classification](http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9745)." AAAI. 2015. [RNN, CNN]
* Tang, Duyu, Bing Qin, and Ting Liu. "[Document modeling with gated recurrent neural network for sentiment classification](http://www.emnlp2015.org/proceedings/EMNLP/pdf/EMNLP167.pdf)." Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. 2015. [RNN]
* Li, Jiwei, Minh-Thang Luong, and Dan Jurafsky. "[A hierarchical neural autoencoder for paragraphs and documents](https://arxiv.org/abs/1506.01057)." arXiv preprint arXiv:1506.01057 (2015). [LSTM, Attention]
* Kiros, Ryan, et al. "[Skip-thought vectors](http://arxiv.org/abs/1506.06726)." Advances in Neural Information Processing Systems. 2015. [RNN, Predict adjacent sentences]
* Dai, Andrew M., and Quoc V. Le. "[Semi-supervised sequence learning](https://arxiv.org/abs/1511.01432)."Advances in Neural Information Processing Systems. 2015. [Initialized LSTM with a sequence autoencoder]
* Kim, Yoon, et al. "[Character-aware neural language models](https://arxiv.org/abs/1508.06615)." arXiv preprint arXiv:1508.06615 (2015). [Character, RNN, CNN, Highway Network]
* Bojanowski, Piotr, Armand Joulin, and Tomas Mikolov. "[Alternative structures for character-level RNNs](http://arxiv.org/abs/1511.06303)." arXiv preprint arXiv:1511.06303 (2015). [Character, RNN]
* Zhang, Xiang, Junbo Zhao, and Yann LeCun. "[Character-level convolutional networks for text classification](http://arxiv.org/abs/1509.01626)." Advances in Neural Information Processing Systems. 2015. [Character, CNN]

## 2014
* Kalchbrenner, Nal, Edward Grefenstette, and Phil Blunsom. "[A convolutional neural network for modelling sentences](http://www.aclweb.org/anthology/P14-1062)." arXiv preprint arXiv:1404.2188(2014). [CNN]
* Denil, Misha, et al. "[Modelling, visualising and summarising documents with a single convolutional neural network](https://arxiv.org/abs/1406.3830)." arXiv preprint arXiv:1406.3830 (2014). [CNN]
* Kim, Yoon. "[Convolutional neural networks for sentence classification](http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf)." arXiv preprint arXiv:1408.5882 (2014). [CNN]
* Pennington, Jeffrey, Richard Socher, and Christopher D. Manning. "[Glove: Global Vectors for Word Representation](http://www-nlp.stanford.edu/pubs/glove.pdf)." EMNLP. Vol. 14. 2014.
* Hu, Baotian, et al. "[Convolutional neural network architectures for matching natural language sentences](http://www.hangli-hl.com/uploads/3/1/6/8/3168008/hu-etal-nips2014.pdf)." Advances in Neural Information Processing Systems. 2014. [CNN]
* Santos, Cicero D., and Bianca Zadrozny. "[Learning character-level representations for part-of-speech tagging](http://jmlr.csail.mit.edu/proceedings/papers/v32/santos14.pdf)." Proceedings of the 31st International Conference on Machine Learning (ICML-14). 2014. [Character, CNN]
* Le, Quoc V., and Tomas Mikolov. "[Distributed representations of sentences and documents](https://arxiv.org/abs/1405.4053)." arXiv preprint arXiv:1405.4053 (2014). [Paragraph Vector]


## 2003-2013
* Bengio, Y.; Ducharme, R.; and Vincent, P. 2003. [A Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf). Journal of Machine Learning Research 3:1137â€“1155. [NNLM]
* Tomas, Mikolov, and Geoffrey Zweig. "[Context dependent recurrent neural network language model](http://www.msr-waypoint.com/pubs/176926/rnn_ctxt.pdf)." SLT. 2012. [Contextual RNNLM]
* Tomas, Mikolov. [Statistical language models based on neural networks](http://www.fit.vutbr.cz/~imikolov/rnnlm/thesis.pdf). Diss. PhD thesis, Brno University of Technology. 2012.[PDF], 2012. [RNNLM]
* Mikolov, Tomas, et al. "[Efficient estimation of word representations in vector space](http://arxiv.org/abs/1301.3781)." arXiv preprint arXiv:1301.3781 (2013).
